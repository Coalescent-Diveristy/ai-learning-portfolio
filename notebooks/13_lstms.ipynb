{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "177d3763",
   "metadata": {},
   "source": [
    "# Long Short-Term Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0cd5fa",
   "metadata": {},
   "source": [
    "# LSTMs\n",
    "\n",
    "LSTMs are a special type of RNN designed to capture long-term dependencies.  \n",
    "They use gates to control what to keep and forget.\n",
    "\n",
    "**Why it matters:**\n",
    "- Handles long sequences better than vanilla RNNs\n",
    "- Widely used in NLP, translation, speech\n",
    "\n",
    "**Key ideas:**\n",
    "- Input, forget, and output gates\n",
    "- Cell state preserves information\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c39e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "\n",
    "X = np.random.random((100,10,1))\n",
    "y = np.random.randint(2, size=(100,1))\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.LSTM(16, input_shape=(10,1)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X,y,epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59597de",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Try these on your own:\n",
    "- Modify the example above\n",
    "- Add a new dataset or parameter\n",
    "- Visualize results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75922e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
